[INFO:] Activating virtual env
[INFO:] DATA FOLDER: /home/ubuntu/DataEngineering_Jobs_Data_ETL_Pipeline/data
[INFO:] SCRIPT FILE: /home/ubuntu/DataEngineering_Jobs_Data_ETL_Pipeline/script/run.sh
[INFO:] LOG FILE FOR run.sh IS AT: /home/ubuntu/DataEngineering_Jobs_Data_ETL_Pipeline/logs/run.sh_19-11-2024-19-56-37.log
[INFO:] PYTHON FILE: /home/ubuntu/DataEngineering_Jobs_Data_ETL_Pipeline/script/run.py
[INFO:] LOG FILE FOR run.py IS AT: /home/ubuntu/DataEngineering_Jobs_Data_ETL_Pipeline/logs/run.py_19-11-2024-19-56-37.log
[DEBUG:] PYTHON_FILE is set to: /home/ubuntu/DataEngineering_Jobs_Data_ETL_Pipeline/script/run.py
[INFO:] RUNNING PYTHON SCRIPT /home/ubuntu/DataEngineering_Jobs_Data_ETL_Pipeline/script/run.py
The shape of the downloaded data is : (20, 5)
The columns in the downloaded data is Index(['company.name', 'locations', 'name', 'type', 'publication_date'], dtype='object')
Data is extracted!
The shape of the dataset is : (20, 5)
The columns in the dataset are: Index(['company.name', 'locations', 'name', 'type', 'publication_date'], dtype='object')
Raw data is saved!
Index(['company_name', 'location', 'job_name', 'job_type', 'date'], dtype='object')
Data is cleaned!
Clean data is saved!
[INFO:] Python script executed successfully.
